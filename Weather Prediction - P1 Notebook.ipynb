{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Pipeline-Notebook.png)\n# Pipeline Notebook - AutoAI Notebook v1.18.4\n\nConsider these tips for working with an auto-generated notebook:\n- Notebook code generated using AutoAI will execute successfully. If you modify the notebook, we cannot guarantee it will run successfully.\n- This pipeline is optimized for the original data set. The pipeline might fail or produce sub-optimal results if used with different data.  If you want to use a different data set, consider retraining the AutoAI experiment to generate a new pipeline. For more information, see <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>. \n- Before modifying the pipeline or trying to re-fit the pipeline, consider that the code converts dataframes to numpy arrays before fitting the pipeline (a current restriction of the preprocessor pipeline).\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"content\"></a>\n## Notebook content\n\nThis notebook contains a Scikit-learn representation of AutoAI pipeline. This notebook introduces commands for retrieving data, training the model, and testing the model. \n\nSome familiarity with Python is helpful. This notebook uses Python 3.10 and scikit-learn 1.1.1."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "## Notebook goals\n\n-  Scikit-learn pipeline definition\n-  Pipeline training \n-  Pipeline evaluation\n\n## Contents\n\nThis notebook contains the following parts:\n\n**[Setup](#setup)**<br>\n&nbsp;&nbsp;[Package installation](#install)<br>\n&nbsp;&nbsp;[AutoAI experiment metadata](#variables_definition)<br>\n&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n**[Pipeline inspection](#inspection)** <br>\n&nbsp;&nbsp;[Read training data with train and test data split](#read)<br>\n&nbsp;&nbsp;[Create pipeline](#preview_model_to_python_code)<br>\n&nbsp;&nbsp;[Train pipeline model](#train)<br>\n&nbsp;&nbsp;[Test pipeline model](#test_model)<br>\n&nbsp;&nbsp;[Forecast](#fore)<br>\n**[Store the model](#saving)**<br>\n**[Summary and next steps](#summary_and_next_steps)**<br>\n**[Copyrights](#copyrights)**"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"setup\"></a>\n# Setup"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"install\"></a>\n## Package installation\nBefore you use the sample code in this notebook, install the following packages:\n - ibm_watson_machine_learning,\n - autoai-ts-libs,\n - scikit-learn\n"
        },
        {
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:00:45.009458Z",
                    "iopub.status.busy": "2020-10-12T14:00:45.007968Z",
                    "iopub.status.idle": "2020-10-12T14:00:46.037702Z",
                    "shell.execute_reply": "2020-10-12T14:00:46.038270Z"
                },
                "pycharm": {
                    "name": "#%%\n"
                },
                "scrolled": true
            },
            "cell_type": "code",
            "source": "!pip install ibm-watson-machine-learning | tail -n 1\n!pip install -U 'autoai-ts-libs>=1.2.0,<4.0' | tail -n 1\n!pip install -U scikit-learn==1.1.1 | tail -n 1",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->ibm-watson-machine-learning) (3.0.9)\nSuccessfully installed alchemy-config-1.1.2 alchemy-logging-1.1.1 anytree-2.9.0 autoai-ts-libs-3.0.8 deprecated-1.2.14 ijson-3.2.2 import-tracker-3.1.5 jsons-1.3.1 munch-4.0.0 semver-3.0.1 typish-1.9.3\nRequirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn==1.1.1) (1.1.1)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"variables_definition\"></a>\n## AutoAI experiment metadata\nThe following cell contains the training data connection details.  \n**Note**: The connection might contain authorization credentials, so be careful when sharing the notebook."
        },
        {
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:00:49.797633Z",
                    "iopub.status.busy": "2020-10-12T14:00:49.796778Z",
                    "iopub.status.idle": "2020-10-12T14:00:57.182715Z",
                    "shell.execute_reply": "2020-10-12T14:00:57.183132Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning.helpers import DataConnection\nfrom ibm_watson_machine_learning.helpers import ContainerLocation\n\ntraining_data_references = [\n    DataConnection(\n        data_asset_id='7c3ecd4f-2708-4870-9de5-788be6c5496d'\n    ),\n]\ntraining_result_reference = DataConnection(\n    location=ContainerLocation(\n        path='auto_ml/f0f38b4e-c962-4e54-94fc-dcf364bb208d/wml_data/327ca112-2310-46b3-98f1-201885ecfe84/data/autoai-ts',\n        model_location='auto_ml/f0f38b4e-c962-4e54-94fc-dcf364bb208d/wml_data/327ca112-2310-46b3-98f1-201885ecfe84/data/autoai-ts/model.zip',\n        training_status='auto_ml/f0f38b4e-c962-4e54-94fc-dcf364bb208d/wml_data/327ca112-2310-46b3-98f1-201885ecfe84/training-status.json'\n    )\n)",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The following cell contains input parameters provided to run the AutoAI experiment in Watson Studio."
        },
        {
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:00:57.187305Z",
                    "iopub.status.busy": "2020-10-12T14:00:57.186602Z",
                    "iopub.status.idle": "2020-10-12T14:00:57.188392Z",
                    "shell.execute_reply": "2020-10-12T14:00:57.188878Z"
                },
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "experiment_metadata = dict(\n    prediction_type='timeseries',\n    prediction_columns=['precipitation', 'temp_max', 'temp_min', 'wind'],\n    csv_separator=',',\n    holdout_size=20,\n    training_data_references=training_data_references,\n    training_result_reference=training_result_reference,\n    timestamp_column_name='date',\n    backtest_num=4,\n    pipeline_type='all',\n    customized_pipelines=[],\n    lookback_window=16,\n    forecast_window=5,\n    max_num_daub_ensembles=3,\n    feature_columns=['precipitation', 'temp_max', 'temp_min', 'wind'],\n    future_exogenous_available=True,\n    gap_len=0,\n    deployment_url='https://us-south.ml.cloud.ibm.com',\n    project_id='2cb847c0-a98a-42d4-93f9-4d49c25d8909',\n    numerical_imputation_strategy=['FlattenIterative', 'Linear', 'Cubic', 'Previous']\n)",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Set `n_jobs` parameter to the number of available CPUs"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import os, ast\nCPU_NUMBER = -1\nif 'RUNTIME_HARDWARE_SPEC' in os.environ:\n    CPU_NUMBER = int(ast.literal_eval(os.environ['RUNTIME_HARDWARE_SPEC'])['num_cpu'])",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"connection\"></a>\n## Watson Machine Learning connection\n\nThis cell defines the credentials required to work with the Watson Machine Learning service.\n\n**Action**: Provide the IBM Cloud apikey, For details, see [documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey)."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "api_key = 'PUT_YOUR_APIKEY_HERE'",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wml_credentials = {\n    \"apikey\": api_key,\n    \"url\": experiment_metadata['deployment_url']\n}",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning import APIClient\n\nwml_client = APIClient(wml_credentials)\n\nif 'space_id' in experiment_metadata:\n    wml_client.set.default_space(experiment_metadata['space_id'])\nelse:\n    wml_client.set.default_project(experiment_metadata['project_id'])\n    \ntraining_data_references[0].set_client(wml_client)\n\n",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Error getting IAM Token.\nReason: <Response [400]>\n",
                    "name": "stderr"
                },
                {
                    "output_type": "error",
                    "ename": "WMLClientError",
                    "evalue": "Error getting IAM Token.\nReason: <Response [400]>",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mibm_watson_machine_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APIClient\n\u001b[0;32m----> 3\u001b[0m wml_client \u001b[38;5;241m=\u001b[39m \u001b[43mAPIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwml_credentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspace_id\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m experiment_metadata:\n\u001b[1;32m      6\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39mdefault_space(experiment_metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspace_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/client.py:356\u001b[0m, in \u001b[0;36mAPIClient.__init__\u001b[0;34m(self, wml_credentials, project_id, verify)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mprint\u001b[39m(Messages\u001b[38;5;241m.\u001b[39mget_message(message_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython_3_7_3_8_framework_are_deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_instance \u001b[38;5;241m=\u001b[39m \u001b[43mServiceInstanceNewPlan\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolumes \u001b[38;5;241m=\u001b[39m Volume(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/instance_new_plan.py:40\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan.__init__\u001b[0;34m(self, client)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# TODO: Check if this is used anywhere.. from initial searches, doesn't seem like\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# self._wml_credentials[u'instance_id'] = \"999\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# This is used in connections.py\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_href_definitions \u001b[38;5;241m=\u001b[39m HrefDefinitions(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m     35\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES,\n\u001b[1;32m     36\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mPLATFORM_URL,\n\u001b[1;32m     37\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCAMS_URL,\n\u001b[1;32m     38\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mwml_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# self._logger.info(u'Successfully prepared token: ' + self._client.wml_token)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# ml_repository_client is initialized in repo\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetails \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/instance_new_plan.py:208\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan._create_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_is_IAM():\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_IAM_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapikey for IAM token is not provided in credentials for the client.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/instance_new_plan.py:261\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan._get_IAM_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expiration_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError getting IAM Token.\u001b[39m\u001b[38;5;124m'\u001b[39m, response)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
                        "\u001b[0;31mWMLClientError\u001b[0m: Error getting IAM Token.\nReason: <Response [400]>"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"inspection\"></a>\n# Pipeline inspection"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "<a id=\"read\"></a>\n## Read training data with train and test data split\n\nRetrieve training dataset from AutoAI experiment as pandas DataFrame.\n\n**Note**: If reading data results in an error, provide data as Pandas DataFrame object, for example, reading .CSV file with `pandas.read_csv()`"
        },
        {
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:01:16.076169Z",
                    "iopub.status.busy": "2020-10-12T14:01:16.075589Z",
                    "iopub.status.idle": "2020-10-12T14:01:19.190233Z",
                    "shell.execute_reply": "2020-10-12T14:01:19.190807Z"
                },
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "train_X, test_X, train_y, test_y = training_data_references[0].read(experiment_metadata=experiment_metadata, with_holdout_split=True, use_flight=False)",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Cannot read saved remote data before fit.\n",
                    "name": "stderr"
                },
                {
                    "output_type": "error",
                    "ename": "CannotReadSavedRemoteDataBeforeFit",
                    "evalue": "Cannot read saved remote data before fit.",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/helpers/connections/connections.py:802\u001b[0m, in \u001b[0;36mDataConnection.read\u001b[0;34m(self, with_holdout_split, csv_separator, excel_sheet, encoding, raw, binary, read_to_file, number_of_batch_rows, sampling_type, sample_size_limit, sample_rows_limit, sample_percentage_limit, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m all_logging_disabled():\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_connection_asset_is_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    803\u001b[0m         cos_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_cos_client()\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/helpers/connections/base_data_connection.py:433\u001b[0m, in \u001b[0;36mBaseDataConnection._check_if_connection_asset_is_s3\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSER_ACCESS_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRUNTIME_ENV_ACCESS_TOKEN_FILE\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/helpers/connections/base_data_connection.py:290\u001b[0m, in \u001b[0;36mBaseDataConnection._check_if_connection_asset_is_s3\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproject_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Project\n\u001b[0;32m--> 290\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43mProject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# note: Check if asset is located directly in the project files\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m#       If yes it is not a connected data.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m#       [Prevents unnecessary logging].\u001b[39;00m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/project_lib/project.py:86\u001b[0m, in \u001b[0;36mProject.access\u001b[0;34m(project_id, auth_token, spark_context)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a Project object for accessing a Watson Studio project.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mAll arguments are optional. Most values can be determined\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mspark_context - the Spark context, if available\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mProject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m               \u001b[49m\u001b[43mproject_access_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m               \u001b[49m\u001b[43mspark_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspark_context\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/project_lib/project.py:42\u001b[0m, in \u001b[0;36mProject.__init__\u001b[0;34m(self, spark_context, project_id, project_access_token, _handle_, _core_)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_core:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_core \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_project_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspark_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# ProjectContext is a legacy concept, older than refreshable tokens\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# and older than optional tokens\u001b[39;00m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/project_lib/handlers/factory.py:20\u001b[0m, in \u001b[0;36mcreate_project_handler\u001b[0;34m(handle, spark_context, api_proxy_factory)\u001b[0m\n\u001b[1;32m     19\u001b[0m projectAPI \u001b[38;5;241m=\u001b[39m api_proxy_factory\u001b[38;5;241m.\u001b[39mnewProjectAPI()\n\u001b[0;32m---> 20\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[43mprojectAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/project_lib/proxies/projects_api.py:49\u001b[0m, in \u001b[0;36mProjectAPIProxy.get_project\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m     pylogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET project failed, status \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m                    response\u001b[38;5;241m.\u001b[39mstatus_code, url, response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to GET project, status: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m                        \u001b[38;5;241m.\u001b[39mformat(response\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Failed to GET project, status: 401",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mCannotReadSavedRemoteDataBeforeFit\u001b[0m        Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_X, test_X, train_y, test_y \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_data_references\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_holdout_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_flight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/helpers/connections/connections.py:826\u001b[0m, in \u001b[0;36mDataConnection.read\u001b[0;34m(self, with_holdout_split, csv_separator, excel_sheet, encoding, raw, binary, read_to_file, number_of_batch_rows, sampling_type, sample_size_limit, sample_rows_limit, sample_percentage_limit, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    825\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSER_ACCESS_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRUNTIME_ENV_ACCESS_TOKEN_FILE\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m CannotReadSavedRemoteDataBeforeFit()\n\u001b[1;32m    828\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_data_from_flight_service(data_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    829\u001b[0m                                                            binary\u001b[38;5;241m=\u001b[39mbinary,\n\u001b[1;32m    830\u001b[0m                                                            read_to_file\u001b[38;5;241m=\u001b[39mread_to_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    839\u001b[0m                                                            total_nrows_limit\u001b[38;5;241m=\u001b[39mtotal_nrows_limit,\n\u001b[1;32m    840\u001b[0m                                                            total_percentage_limit\u001b[38;5;241m=\u001b[39mtotal_percentage_limit)\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m DataConnectionTypes\u001b[38;5;241m.\u001b[39mFS:\n",
                        "\u001b[0;31mCannotReadSavedRemoteDataBeforeFit\u001b[0m: Cannot read saved remote data before fit."
                    ]
                }
            ]
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "<a id=\"preview_model_to_python_code\"></a>\n## Create pipeline\nIn the next cell, you can find the Scikit-learn definition of the selected AutoAI pipeline."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Import statements."
        },
        {
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "from autoai_ts_libs.utils.ts_pipeline import TSPipeline\nfrom autoai_ts_libs.transforms.imputers import linear\nfrom autoai_ts_libs.sklearn.autoai_ts_pipeline import AutoaiTSPipeline\nfrom autoai_ts_libs.sklearn.mvp_windowed_transformed_target_estimators import (\n    AutoaiWindowTransformedTargetRegressor,\n)\nfrom autoai_ts_libs.sklearn.small_data_window_transformers import (\n    SmallDataWindowTransformer,\n)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Pipeline definition."
        },
        {
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "linear = linear(missing_val_identifier=float(\"nan\"))\nsmall_data_window_transformer = SmallDataWindowTransformer(lookback_window=16)\nsimple_imputer = SimpleImputer(missing_values=float(\"nan\"))\nrandom_forest_regressor = RandomForestRegressor(\n    n_estimators=500, max_depth=30, n_jobs=CPU_NUMBER, random_state=33\n)\nautoai_ts_pipeline_0 = AutoaiTSPipeline(\n    steps=[\n        (\"WTX\", small_data_window_transformer),\n        (\"imputer\", simple_imputer),\n        (\"est\", random_forest_regressor),\n    ]\n)\nautoai_window_transformed_target_regressor = (\n    AutoaiWindowTransformedTargetRegressor(\n        feature_columns=[0, 1, 2, 3],\n        lookback_window=16,\n        prediction_horizon=5,\n        random_state=33,\n        regressor=autoai_ts_pipeline_0,\n        short_name=\"WindowRandomForest\",\n        target_columns=[0, 1, 2, 3],\n    )\n)\nautoai_ts_pipeline = AutoaiTSPipeline(\n    steps=[(\"windowedttr\", autoai_window_transformed_target_regressor)]\n)\npipeline = TSPipeline(\n    steps=[\n        (\"linear_imputer\", linear),\n        (\n            \"<class 'autoai_ts_libs.sklearn.autoai_ts_pipeline.AutoaiTSPipeline'>\",\n            autoai_ts_pipeline,\n        ),\n    ],\n    feature_columns=[0, 1, 2, 3],\n    prediction_horizon=5,\n    target_columns=[0, 1, 2, 3],\n)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"train\"></a>\n## Train pipeline model\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Define scorer from the optimization metric\nThis cell constructs the cell scorer based on the experiment metadata."
        },
        {
            "metadata": {
                "pycharm": {
                    "is_executing": true
                }
            },
            "cell_type": "code",
            "source": "from autoai_ts_libs.utils.metrics import get_scorer\n\nscorer = get_scorer(\"neg_avg_symmetric_mean_absolute_percentage_error\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "<a id=\"test_model\"></a>\n### Fit pipeline model\nIn this cell, the pipeline is fitted."
        },
        {
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:01:19.291734Z",
                    "iopub.status.busy": "2020-10-12T14:01:19.244735Z",
                    "iopub.status.idle": "2020-10-12T14:01:19.338461Z",
                    "shell.execute_reply": "2020-10-12T14:01:19.338958Z"
                },
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                },
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pipeline.fit(train_X.values, train_y.values);",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'pipeline' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_X\u001b[38;5;241m.\u001b[39mvalues, train_y\u001b[38;5;241m.\u001b[39mvalues)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"test_model\"></a>\n## Test pipeline model"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Score the fitted pipeline with the generated scorer using the holdout dataset."
        },
        {
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:02:03.910267Z",
                    "iopub.status.busy": "2020-10-12T14:02:03.909710Z",
                    "iopub.status.idle": "2020-10-12T14:02:03.914154Z",
                    "shell.execute_reply": "2020-10-12T14:02:03.914727Z"
                },
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "score = scorer(pipeline, test_X.values, test_y.values)\nprint(score)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipeline.predict(test_X.values)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"forecast\"></a>\n## Forecast\n\nForecast the future values of targets."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipeline.predict()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Forecasting with the new observations\nProvide new observations values\nFor example:\n - `a,b` are both targets and features, taken from `experiment_metadata[\"prediction_columns\"]`\n\n```\nimport numpy as np\n\na_newObs = [12, 22, 35, 46]\nb_newObs = [34, 23, 45, 34]\nnewObs = np.mat([a_newObs, b_newObs]).T\npipeline.predict(newObs)\n```\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"saving\"></a>\n## Store the model\n\nIn this section you will learn how to store the retrained model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "model_metadata = {\n    wml_client.repository.ModelMetaNames.NAME: 'P1 - Pretrained AutoAI pipeline'\n}\n\nstored_model_details = wml_client.repository.store_model(model=pipeline, meta_props=model_metadata, experiment_metadata=experiment_metadata)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Inspect the stored model details."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "stored_model_details",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"summary_and_next_steps\"></a>\n# Summary and next steps\nYou successfully completed this notebook!\nYou learned how to use AutoAI pipeline definition to train the model.\nCheck out our [Online Documentation](https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_latest/cpd/overview/relnotes-4.0.html) for more samples, tutorials, documentation, how-tos, and blog posts."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the ILAN License. Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>\n\n___"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.10",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}